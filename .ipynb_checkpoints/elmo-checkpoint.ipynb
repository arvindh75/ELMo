{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cb562b5-1c0b-4bb8-b269-833ffcff65d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2abdb5cd-ee25-4686-a193-40e4cba77da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from numpy import dot\n",
    "from torch import optim\n",
    "from collections import Counter\n",
    "from numpy.linalg import norm\n",
    "from tqdm.auto import tqdm\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c1c6c4-b207-49c6-a4dd-b8a7fcafa7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "MODE = \"TEST\"\n",
    "LR = 1e-5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b157b33-ce82-42ac-af14-784c254a9f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_FILTERS = list()\n",
    "CONV_FILTERS.append([1, 32])\n",
    "CONV_FILTERS.append([2, 32])\n",
    "CONV_FILTERS.append([3, 64])\n",
    "CONV_FILTERS.append([4, 128])\n",
    "CONV_FILTERS.append([5, 256])\n",
    "CONV_FILTERS.append([6, 512])\n",
    "CONV_FILTERS.append([7, 1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf256833-92bc-4873-bc8c-1d04d3608f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIGHWAY = 2\n",
    "CHAR_EMBED_DIM = 50\n",
    "WORD_EMBED_DIM = 300\n",
    "MAX_CHAR = 50\n",
    "MIN_COUNT = 5\n",
    "MAX_LEN = 256\n",
    "OUTPUT_DIM = 150\n",
    "NUM_UNITS = 256\n",
    "NUM_LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c83a1c9-db3a-48b2-8643-f8f40ad251a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"TRAIN\":\n",
    "    with open(\"./data/corpus.json\") as f:\n",
    "        CORPUS = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46972562-aaae-43ce-9f05-b24d8332031e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device - cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "print(\"device - \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cbf8924-d219-40d9-a102-5d4011bffef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov  8 19:23:47 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.95.01    Driver Version: 440.95.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 30%   28C    P0    63W / 250W |     11MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 30%   25C    P0    47W / 250W |     11MiB / 11019MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9503ef6f-2a2f-404e-84c0-ec4eb01807e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "265c35eb-d982-4c11-b35d-d49f4669f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, word2id, char2id):\n",
    "        self.word2id = word2id\n",
    "        self.char2id = char2id\n",
    "        self.id2word = {i: word for word, i in word2id.items()}\n",
    "        self.id2ch = {i: char for char, i in char2id.items()}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_corpus(cls, corpus, min_count=5):\n",
    "        word_count = Counter()\n",
    "        for sentence in corpus:\n",
    "            word_count.update(sentence.lower().split())\n",
    "        word_count = list(word_count.items())\n",
    "        word_count.sort(key=lambda x: x[1], reverse=True)\n",
    "        for i, (word, count) in enumerate(word_count):\n",
    "            if count < min_count:\n",
    "                break\n",
    "        vocab = word_count[:i]\n",
    "        vocab = [v[0] for v in vocab]\n",
    "        word_lexicon = {}\n",
    "        for special_word in ['<oov>', '<pad>']:\n",
    "            if special_word not in word_lexicon:\n",
    "                word_lexicon[special_word] = len(word_lexicon)\n",
    "        for word in vocab:\n",
    "            if word not in word_lexicon:\n",
    "                word_lexicon[word] = len(word_lexicon)\n",
    "        char_lexicon = {}\n",
    "        for special_char in ['<oov>', '<pad>']:\n",
    "            if special_char not in char_lexicon:\n",
    "                char_lexicon[special_char] = len(char_lexicon)\n",
    "        for sentence in corpus:\n",
    "            for word in sentence.split():\n",
    "                for ch in word:\n",
    "                    if ch not in char_lexicon:\n",
    "                        char_lexicon[ch] = len(char_lexicon)\n",
    "        return cls(word_lexicon,char_lexicon)\n",
    "    \n",
    "    def tokenize(self,text,max_length=512,max_char=50):\n",
    "        oov_id, pad_id = self.word2id.get(\"<oov>\"), self.word2id.get(\"<pad>\")\n",
    "        w = torch.LongTensor(max_length).fill_(pad_id)\n",
    "        words = text.lower().split()\n",
    "        for i, wi in enumerate(words[:max_length]):\n",
    "            w[i] = self.word2id.get(wi, oov_id)\n",
    "        oov_id, pad_id = self.char2id.get(\"<oov>\"), self.char2id.get(\"<pad>\")\n",
    "        c = torch.LongTensor(max_length,max_char).fill_(pad_id)\n",
    "        for i, wi in enumerate(words[:max_length]):\n",
    "            for j,wij in enumerate(wi[:max_char]):\n",
    "                c[i][j]=self.char2id.get(wij, oov_id)\n",
    "        return w, c, len(words[:max_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "439f73f4-1bba-48d9-a6a4-e9dbdee8d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"TRAIN\":\n",
    "    TOKENIZER = Tokenizer.from_corpus(CORPUS, MIN_COUNT)\n",
    "else:\n",
    "    with open(f\"./checkpoints/tokenizer.json\") as f:\n",
    "        d = json.load(f)\n",
    "    TOKENIZER = Tokenizer(d[\"word2id\"], d[\"ch2id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad522632-bfb1-4308-a303-58c7bec83137",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CONV_FILTERS = sum(z[1] for z in CONV_FILTERS)\n",
    "FINAL_EMBED_DIM = WORD_EMBED_DIM + N_CONV_FILTERS\n",
    "char2id_len = len(TOKENIZER.char2id)\n",
    "word2id_len = len(TOKENIZER.word2id)\n",
    "PADDING_INDX_CHAR = TOKENIZER.char2id.get(\"<pad>\")\n",
    "PADDING_INDX_WORD = TOKENIZER.word2id.get(\"<pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3029d240-7e53-41d9-832e-a673df56871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class elmoDS(Dataset):\n",
    "    def __getitem__(self, indx):\n",
    "        text = CORPUS[indx]\n",
    "        word, char, i = TOKENIZER.tokenize(text, max_length = MAX_LEN, max_char = MAX_CHAR)\n",
    "        return char, word, i\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(CORPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37aad37c-7c33-411f-a322-1435370ac1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"TRAIN\":\n",
    "    data = elmoDS()\n",
    "    data_loader = DataLoader(data, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7da431f-48db-4e52-915b-435a2678f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspirations form https://gist.github.com/Redchards/65f1a6f758a1a5c5efb56f83933c3f6e\n",
    "class Highway(nn.Module):\n",
    "    def __init__(self, inp_dim, n_layers, activation):\n",
    "        super(Highway, self).__init__()\n",
    "        self.inp_dim = inp_dim\n",
    "        self.layers = nn.ModuleList([nn.Linear(inp_dim, inp_dim * 2) for i in range(n_layers)])\n",
    "        self.activation = activation\n",
    "        for layer in self.layers:\n",
    "            layer.bias[inp_dim:].data.fill_(1)\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        cur_inp = inp\n",
    "        for l in self.layers:\n",
    "            proj_inp = l(cur_inp)\n",
    "            l_p = cur_inp\n",
    "            nl_p = self.activation(proj_inp[:, 0 : self.inp_dim])\n",
    "            g = torch.sigmoid(proj_inp[:, self.inp_dim : (2 * self.inp_dim)])\n",
    "            cur_inp = g * l_p + (1 - g) * nl_p\n",
    "        return cur_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9d3627c-ed20-431f-a7b3-f2cc9f0e4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class elmo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(elmo, self).__init__()\n",
    "        self.char_e = nn.Embedding(char2id_len, CHAR_EMBED_DIM, padding_idx = PADDING_INDX_CHAR)\n",
    "        self.word_e = nn.Embedding(word2id_len, WORD_EMBED_DIM, padding_idx = PADDING_INDX_WORD)\n",
    "        self.activation = nn.ReLU()\n",
    "        conv_list = []\n",
    "        for w, h in CONV_FILTERS:\n",
    "            conv_list.append(nn.Conv1d(in_channels = CHAR_EMBED_DIM, out_channels = h, kernel_size = w, bias = True))\n",
    "        self.convs = nn.ModuleList(conv_list)\n",
    "        self.highway = Highway(N_CONV_FILTERS, NUM_HIGHWAY, activation = self.activation)\n",
    "        self.proj = nn.Linear(FINAL_EMBED_DIM, OUTPUT_DIM, bias = True)\n",
    "        fLSTM = []\n",
    "        bLSTM = []\n",
    "        for x in range(NUM_LAYERS):\n",
    "            if x == 0:\n",
    "                fLSTM.append(nn.LSTM(input_size = OUTPUT_DIM, hidden_size = NUM_UNITS, batch_first = True))\n",
    "                bLSTM.append(nn.LSTM(input_size = OUTPUT_DIM, hidden_size = NUM_UNITS, batch_first = True))\n",
    "            else:\n",
    "                fLSTM.append(nn.LSTM(input_size = NUM_UNITS, hidden_size = NUM_UNITS, batch_first = True))\n",
    "                bLSTM.append(nn.LSTM(input_size = NUM_UNITS, hidden_size = NUM_UNITS, batch_first = True))\n",
    "        self.fLSTM = nn.ModuleList(fLSTM)\n",
    "        self.bLSTM = nn.ModuleList(bLSTM)\n",
    "        self.linL = nn.Linear(in_features = NUM_UNITS, out_features = word2id_len)\n",
    "    \n",
    "    def forward(self, char_input, word_input):\n",
    "        embeddings = []\n",
    "        batch_size = word_input.size(0)\n",
    "        seq_len = word_input.size(1)\n",
    "        embeddings.append(self.word_e(Variable(word_input)))\n",
    "        char_input = char_input.view(batch_size * seq_len, -1)\n",
    "        char_em = self.char_e(Variable(char_input)).transpose(1, 2)\n",
    "        conv_list = []\n",
    "        for x in range(len(self.convs)):\n",
    "            c, temp = torch.max(self.convs[x](char_em), dim = -1)\n",
    "            conv_list.append(self.activation(c))\n",
    "        char_em = self.highway(torch.cat(conv_list, dim = -1))\n",
    "        embeddings.append(char_em.view(batch_size, -1, N_CONV_FILTERS))\n",
    "        embeddings = self.proj(torch.cat(embeddings, dim = 2))\n",
    "        forward = []\n",
    "        backward = []\n",
    "        forward.append(embeddings)\n",
    "        backward.append(embeddings)\n",
    "        for f_layer, b_layer in zip(self.fLSTM, self.bLSTM):\n",
    "            forward.append(f_layer(forward[-1])[0])\n",
    "            backward.append(torch.flip(b_layer(torch.flip(backward[-1], dims = [1, ]))[0], dims = [1, ]))\n",
    "        return forward, backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65cdaa9-7227-43ad-93da-5bdeb234b521",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e74944b-e755-498f-a26c-8a5c849c54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = elmo()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbea71-429d-49a3-b483-39f92735cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr = LR)\n",
    "loss_func = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f55e4f4-203f-475f-954d-c26199f2b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./checkpoints/tokenizer.json\", \"w\") as f:\n",
    "    json.dump({\"word2id\": TOKENIZER.word2id, \"char2id\": TOKENIZER.char2id}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b5c15-dc11-4ec3-ae1a-7e4010931497",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    print(f\"Epoch - {epoch}\")\n",
    "    for batch in tqdm(data_loader):\n",
    "        total_loss = 0\n",
    "        chars, words, i = batch\n",
    "        chars = chars.to(device)\n",
    "        words = words.to(device)\n",
    "        forward, backward = model(chars, words)\n",
    "        forward = forward[-1]\n",
    "        backward = backward[-1]\n",
    "        max_k = torch.max(i)\n",
    "        loss = 0\n",
    "        for k in range(1, max_k):\n",
    "            fp = forward[:, k-1, :]\n",
    "            bp = backward[:, k-1, :]\n",
    "            f_layer = model.linL(fp).squeeze()\n",
    "            b_layer = model.linL(bp).squeeze()\n",
    "            f_loss = torch.nn.functional.log_softmax(f_layer, dim = 1).squeeze()\n",
    "            b_loss = torch.nn.functional.log_softmax(b_layer, dim = 1).squeeze()\n",
    "            loss += loss_func(f_loss, words[:, k]) \n",
    "            loss += loss_func(b_loss, words[:, k])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        model.zero_grad()\n",
    "        total_loss += loss.detach().item()\n",
    "    \n",
    "    if epoch%2 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'loss': total_loss,\n",
    "        }, f\"./checkpoints/model.pt\")\n",
    "    print(f\"Total Loss - {total_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f975a891-6df2-4350-a1e7-f9684684ac5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45b0ee30-ac38-41e5-9ecf-0dec0020be02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "elmo(\n",
       "  (char_e): Embedding(45, 50, padding_idx=1)\n",
       "  (word_e): Embedding(10742, 300, padding_idx=1)\n",
       "  (activation): ReLU()\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
       "    (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
       "    (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
       "    (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
       "    (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
       "    (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
       "    (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
       "  )\n",
       "  (highway): Highway(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "    )\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (proj): Linear(in_features=2348, out_features=150, bias=True)\n",
       "  (fLSTM): ModuleList(\n",
       "    (0): LSTM(150, 256, batch_first=True)\n",
       "    (1): LSTM(256, 256, batch_first=True)\n",
       "  )\n",
       "  (bLSTM): ModuleList(\n",
       "    (0): LSTM(150, 256, batch_first=True)\n",
       "    (1): LSTM(256, 256, batch_first=True)\n",
       "  )\n",
       "  (linL): Linear(in_features=256, out_features=10742, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = elmo()\n",
    "model.load_state_dict(torch.load(f\"./checkpoints/model.pt\"), strict=False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e24858aa-bd5d-41e3-82b7-5c2096cfea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euc_dist(v1, v2):\n",
    "    return np.linalg.norm(v1 - v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b22999fe-532f-4070-b523-980b92c90d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2)/(np.linalg.norm(v1) * norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0db7d0aa-ae28-40ae-ae5e-14d1ac1a8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_embeddings(sentence, word):\n",
    "    indx = sentence.split().index(word)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        words, chars, i = TOKENIZER.tokenize(sentence, max_length = MAX_LEN)\n",
    "        chars = chars.unsqueeze(0).to(device)\n",
    "        words = words.unsqueeze(0).to(device)\n",
    "        forward, backward = model(chars, words)\n",
    "        en_embedding = forward[0][0][indx].cpu().detach().numpy()\n",
    "        h = list()\n",
    "        for x in range(1, len(forward)):\n",
    "            h.append(torch.cat((forward[x][0][indx], backward[x][0][indx])).cpu().detach().numpy())\n",
    "    return np.mean(h, axis = 0) # Can be modified as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "802ec7de-f434-4402-94e9-ae2926a92b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c575b057-fd13-43d9-a25e-cf6757d72373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256]) torch.Size([1, 256, 50])\n",
      "torch.Size([1, 256]) torch.Size([1, 256, 50])\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"I love the fall season\"\n",
    "sentence2 = \"Try not to fall down while balancing\"\n",
    "word = \"fall\"\n",
    "fall1 = gen_embeddings(sentence1, word)\n",
    "fall2 = gen_embeddings(sentence2, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca11b48b-22c5-4537-8ff8-504c763eff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256]) torch.Size([1, 256, 50])\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I love the climate in October\"\n",
    "word = \"climate\"\n",
    "climate = gen_embeddings(sentence, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a7341ab-ed33-4072-8769-4faca210ecc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7560704"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(fall1, climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5dc6dbab-9a73-4e8a-928a-82cf5aa17360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75236464"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(fall2, climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2546a962-87dc-4ac6-b4b6-4097c18bc16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"He is the king of this region\"\n",
    "sentence2 = \"In chess queen is the strongest player\"\n",
    "word1 = \"king\"\n",
    "word2 = \"queen\"\n",
    "e11 = gen_embeddings(sentence1, word1)\n",
    "e12 = gen_embeddings(sentence2, word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0320bba-38d1-4229-92af-31c1fa1e4d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"I like coffee on rainy evenings\"\n",
    "sentence2 = \"The British love tea parties\"\n",
    "word1 = \"coffee\"\n",
    "word2 = \"tea\"\n",
    "e21 = gen_embeddings(sentence1, word1)\n",
    "e22 = gen_embeddings(sentence2, word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5cf83059-a9dd-4915-9200-21d339b0af11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68156594, 0.487584)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(e11, e12), euc_dist(e11, e12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a4c4af1-9e74-4330-ae42-b5b2d41791d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.645162, 0.520971)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(e21, e22), euc_dist(e21, e22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "573324b8-a15c-49be-a2a3-5aaca8d534fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65949446, 0.5130724)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(e11, e21), euc_dist(e11, e21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3eb60e79-4cfe-40ad-a488-ae0a4ae9eaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6648604, 0.5018805)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(e11, e22), euc_dist(e11, e22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31ad8eba-f001-4e58-adc0-4544e6b58597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6492329, 0.5163286)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(e12, e21), euc_dist(e12, e21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ede35e82-926c-489a-9036-00966222db22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.671428, 0.492364)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(e12, e22), euc_dist(e12, e22)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
